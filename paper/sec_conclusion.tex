\section{Conclusion}
\label{sec:conclusion}

In this paper, we studied the relationship between adversarial robustness, specifically considering robust overfitting \cite{RiceICML2020}, and flatness of the robust loss (\RCE) landscape \wrt perturbations in the weight space. We introduced both average- and worst-case measures for flatness in \RCE that are scale-invariant and allow comparison across models. Considering adversarial training (AT) and several popular variants, including TRADES \cite{ZhangICML2019}, AT-AWP \cite{WuNIPS2020} or AT with additional unlabeled examples \cite{CarmonNIPS2019}, we show a \textbf{clear relationship between adversarial robustness and flatness} in \RCE. More robust methods predominantly find flatter minima. Vice versa, approaches known to improve flatness, \eg, Entropy-SGD \cite{ChaudhariICLR2017} or weight clipping \cite{StutzMLSYS2021} can help AT become more robust, as well. Moreover, even simple regularization methods such as AutoAugment \cite{CubukARXIV2018}, weight decay or label noise, are effective in increasing robustness by improving flatness. These observations also generalize to pre-trained models from RobustBench \cite{CroceARXIV2020b}. 